__author__ = 'Vince'
#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
import sys
reload(sys)
sys.setdefaultencoding('utf-8')

import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn import svm
from sklearn.cross_validation import cross_val_score
from sklearn.cross_validation import train_test_split
from sklearn import metrics
from sklearn import grid_search
from sklearn.preprocessing import Normalizer
from random import randint
import logging
from pprint import pprint
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from time import time
from scipy import interp
import math
import re
from sklearn.metrics import roc_curve, auc
from sklearn.cross_validation import StratifiedKFold
from sklearn.svm import LinearSVC
from collections import OrderedDict
from scipy.io import mmwrite
from sklearn.tree import DecisionTreeClassifier
import time

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('sys.stdout')


def NewLineTokenizer(str):
    return str.split('\n')


def Classification(MalwareCorpus,
                   GoodwareCorpus,
                   Split):
    '''
    :param String MalwareCorpus:
    :param String GoodwareCorpus:
    :param Integer Split:
    '''

    f = open('Data'+os.path.sep+'ClassificationReport.txt','w')
    origin = sys.stdout
    sys.stdout=f

    # step 1 - split all samples to training set and test set
    logger.debug("Loading positive and negative samples file basename")
    MalSamples = [os.path.join(MalwareCorpus, f) for f in os.listdir(MalwareCorpus) if f.endswith('.Features')]
    GoodSamples = [os.path.join(GoodwareCorpus, f) for f in os.listdir(GoodwareCorpus) if f.endswith('.Features')]

    logger.info ("All Samples loaded")
    print '# Mal samples:', len(MalSamples)
    print '# Ben samples:', len(GoodSamples)

    # step 2 - split the dataset into training and testing sets
    TrainMalSamples, TestMalSamples = train_test_split(MalSamples, test_size=Split, random_state=randint(0,99))
    TrainGoodSamples, TestGoodSamples = train_test_split(GoodSamples, test_size=Split, random_state=randint(0,99))
    logger.info("Training and test sets split randomly")

    TrainMalLabels = np.ones(len(TrainMalSamples)).tolist()
    TestMalLabels = np.ones(len(TestMalSamples)).tolist()
    TrainGoodLabels = np.empty(len(TrainGoodSamples)); TrainGoodLabels.fill(-1); TrainGoodLabels = TrainGoodLabels.tolist()
    TestGoodLabels = np.ones(len(TestGoodSamples)); TestGoodLabels.fill(-1); TestGoodLabels = TestGoodLabels.tolist()
    logger.info("All labels created")

    TrainSamples = TrainMalSamples + TrainGoodSamples
    TestSamples = TestMalSamples + TestGoodSamples
    TrainLabels = TrainMalLabels + TrainGoodLabels
    TestLabels = TestMalLabels + TestGoodLabels

    del MalSamples, GoodSamples
    logger.info("All Samples loaded into training and testing sets")
    print "# Train Samples", len(TrainSamples)
    print "# Train Labels", len(TrainLabels)
    print "# Test Samples", len(TestSamples)
    print "# Test Labels", len(TestLabels)

    # step 3 - feature extracting
    NewLineCVetorizer = CountVectorizer(input=u'filename', lowercase=False, token_pattern=None,
                                        tokenizer=NewLineTokenizer, binary=False, dtype=np.float64)

    print 'Performing count vectorizing'
    To=time.time()
    TrainDocsTermsFVs = NewLineCVetorizer.fit_transform(TrainSamples)
    TestDocsTermsFVs = NewLineCVetorizer.transform(TestSamples)
    print time.time()-To
    print 'Train Term-doc Matrix: ', TrainDocsTermsFVs.shape  # rows * cols, rows = docs, cols = features/terms
    print 'Test Term-doc Matrix: ', TestDocsTermsFVs.shape

    # step 4 - Classification
    Clf = LinearSVC(random_state=0)
    BestModel = Clf.fit (TrainDocsTermsFVs, TrainLabels)

    # step 5 - Evaluate the best model on test set
    PredictedLabels = BestModel.predict(TestDocsTermsFVs)
    Accuracy = np.mean(PredictedLabels == TestLabels)
    print time.time()-To
    print "Test Set Accuracy = ", Accuracy
    print (metrics.classification_report(TestLabels, PredictedLabels, target_names=['Benign', 'Malware']))
    print 'Top features'
    print '-----------'
    Vocab = NewLineCVetorizer.get_feature_names()
    FeautureImportances = Clf.coef_[0]
    TopFeatureIndices = FeautureImportances.argsort()[-100:][::-1]
    # Record Top 100 Features of whole dataset
    for FIndex in TopFeatureIndices:
        print Vocab[FIndex], FeautureImportances[FIndex]
    # Record Top 100 Features of each sample
    print 'Train samples'
    print '-------------'
    for i in range(len(TrainSamples)):
        Fv = TrainDocsTermsFVs.toarray()[i]
        Res = Fv * FeautureImportances
        TopRes = Res.argsort()[-100:][::-1]
        print os.path.basename(TrainSamples[i]).replace('.Features', '.apk')
        for SIndex in TopRes:
            if not Fv[SIndex] == 0:
                print Vocab[SIndex]
        print "\n"
        print '-'*50
    print 'Test samples'
    print '------------'
    for i in range(len(TestSamples)):
        Fv = TestDocsTermsFVs.toarray()[i]
        Res = Fv * FeautureImportances
        TopRes = Res.argsort()[-100:][::-1]
        print os.path.basename(TestSamples[i]).replace('.Features', '.apk')
        for SIndex in TopRes:
            if not Fv[SIndex] == 0:
                print Vocab[SIndex]
        print "\n"
        print '-'*50