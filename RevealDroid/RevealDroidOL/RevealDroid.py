__author__ = 'Vince'
#!/usr/bin/python
# -*- coding: utf-8 -*-

import os
import sys
from xml.dom import minidom
import json
import shutil
from GlobalData import *
import multiprocessing as mp
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn import svm
from sklearn.cross_validation import cross_val_score
from sklearn.cross_validation import train_test_split
from sklearn import metrics
from sklearn import grid_search
from sklearn.preprocessing import Normalizer
from random import randint
import logging
from pprint import pprint
from sklearn.feature_selection import SelectKBest, chi2, f_classif
from time import time
from scipy import interp
import math
import re
from sklearn.metrics import roc_curve, auc
from sklearn.cross_validation import StratifiedKFold
from sklearn.svm import LinearSVC
from collections import OrderedDict
from scipy.io import mmwrite
from sklearn.tree import DecisionTreeClassifier
import time
from sklearn.externals import joblib

with open('SusiAPISrcDict.json', 'r') as f0:
    SusiApiSrcMap = json.load(f0)
with open('SusiAPISinkDict.json', 'r') as f1:
    SusiApiSinkMap = json.load(f1)

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('sys.stdout')


def decompile(App):
    '''

    :param App:
    :return:
     
    '''
    f = open('Data'+os.path.sep+'ApktoolReport.txt','w')
    origin=sys.stdout
    sys.stdout=f
    try:
        apktool_command = "java -jar apktool_2.0.2.jar d -f "+ App
        os.system(apktool_command)
    except Exception as e:
        print e
        logger.error(e)
        logger.error("Decompiling "+App+" to get bytecode Failed.")
        return




def getAPI(Smalifile_Linelist):
    '''

    :param Smalifile_Linelist:
    :return:
    
    '''
    api_List=[]
    for word in Smalifile_Linelist:
        word = word.replace(' ','')
        if word.startswith("invoke-"):
            Parts = word.split(",")
            for Part in Parts:
                if ";->" in Part:
                    Part = Part.strip()
                    for APIPrefix in AndroidAPIs:
                        if Part.startswith(APIPrefix):
                            apiParts = Part.split(";->")
                            ApiClass = apiParts[0].strip()
                            ApiName = apiParts[1].split("(")[0].strip()
                            api_List.append(ApiClass+' '+ApiName)
    return api_List

def getAPI_SusiCat(ApiList, SrcMap, SnkMap):
    '''
    
    :param ApiList: 
    :param SrcMap: 
    :param SnkMap: 
    :return:
    '''
    api_SusiCat_List = []
    for Api in ApiList:
        if Api.startswith ('L'): Api = Api[1:]
        Api = Api.replace('/', '.')
        if Api in SrcMap.keys():
            SrcSnk = SrcMap[Api]
            api_SusiCat_List.append('API-<SRC'+SrcSnk+'>')
        elif Api in SnkMap.keys():
            if ' 'in SnkMap[Api]:
                SrcSnk=SnkMap[Api].replace('(','API-<SNK(').replace(')',')>').split(' ')
                api_SusiCat_List=api_SusiCat_List+SrcSnk
            else:
                SrcSnk = SnkMap[Api]
                api_SusiCat_List.append('API-<SNK'+SrcSnk+'>')
    return api_SusiCat_List


def getIAfromXML(Decompilation_dir):
    '''

    :param Decompilation_dir:
    :return:
    
    '''
    ia_fromXML_List=[]
    file=Decompilation_dir+os.path.sep+'AndroidManifest.xml'
    doc = minidom.parse(file)
    root = doc.documentElement
    nodes = root.getElementsByTagName('intent-filter')
    for node in nodes:
        for subnode in node.getElementsByTagName('action'):
            if subnode.getAttribute('android:name') in AndroidIAs:
                ia_fromXML_List.append('IA-<'+subnode.getAttribute('android:name').split('.')[-1]+'>')
    return ia_fromXML_List

def getIAfromSmali(Smalifile_Linelist):
    '''

    :param Smalifile_Linelist:
    :return:
    '''
    ia_fromSmali_List=[]
    for word in Smalifile_Linelist:
        word = word.strip()
        Parts = word.split(' ')
        for Part in Parts:
            for ia in AndroidIAs:
                if ia in Part:
                    ia_fromSmali_List.append('IA-<'+ia.split('.')[-1]+'>')
    return ia_fromSmali_List

def getPkgAPI(API_List):
    '''

    :param API_List:
    :return:
    '''
    papi_DictofLists = {}
    for API in API_List:
        APIClass=os.path.dirname(API[1:].replace('/',os.path.sep))
        papi_DictofLists['PAPI-<'+APIClass.replace(os.path.sep,'.')+'>']= []
    for API in API_List:
        APIClass=os.path.dirname(API[1:].replace('/',os.path.sep))
        if API.startswith ('L'): API = API[1:]
        API = API.replace('/', '.')
        papi_DictofLists['PAPI-<'+APIClass.replace(os.path.sep,'.')+'>'].append(API)
    return papi_DictofLists

def FeatureExtraction(App,dir,feature_option):
    '''

    :param App:
    :param dir:
    :return:
    '''
    API_List = []
    API_FrqDict = {}
    Flow_SusiCat_List = []
    Flow_FrqDict = {}
    IA_List = []
    IA_FrqDict = {}
    PAPIDict={}
    IAfromSmaliList = []
    decompilation_dir=os.path.basename(App)[:-4]

    if not os.path.exists('Data'+os.path.sep+dir +os.path.sep+decompilation_dir+'.Features'):
        decompile(App)
        for root, dirs, smalifiles in os.walk(decompilation_dir):
            for smali in smalifiles:
                if smali.endswith('.smali'):
                    if 'smali'+os.path.sep in os.path.dirname(os.path.join(root,smali)):
                        smalifile=os.path.join(root,smali)
                        with open(smalifile,'r') as f_read:
                            LineList=f_read.readlines()
                            API_List=API_List+getAPI(LineList)
                            IAfromSmaliList=IAfromSmaliList+getIAfromSmali(LineList)
        with open('Metadata'+os.path.sep+dir+os.path.sep+ decompilation_dir+'_API.txt','w') as f_w0:
            for word in API_List:
                print >> f_w0,word
        APISusiList=getAPI_SusiCat(API_List, SusiApiSrcMap, SusiApiSinkMap)

        with open('Data'+os.path.sep+dir+os.path.sep+ decompilation_dir+'_APIFeature.txt','w') as f_write1:
            for Elem in APISusiList:
                if API_FrqDict.has_key(Elem):  API_FrqDict[Elem]=API_FrqDict[Elem]+1
                else:  API_FrqDict[Elem]=1
            for word in APISusiList:
                print >> f_write1,word

        IA_List = getIAfromXML(decompilation_dir)+IAfromSmaliList
        with open('Metadata'+os.path.sep+dir+os.path.sep+ decompilation_dir+'_IA.txt','w') as f_w1:
            for word in IA_List:
                print >> f_w1,word
        with open('Data'+os.path.sep+dir +os.path.sep+decompilation_dir+'_IAFeature.txt','w') as f_write3:
            for Elem in IA_List:
                if IA_FrqDict.has_key(Elem):  IA_FrqDict[Elem]=IA_FrqDict[Elem]+1
                else:  IA_FrqDict[Elem]=1
            for word in IA_List:
                print >> f_write3,word

        PAPIDict = getPkgAPI(API_List)
        with open('Data'+os.path.sep+dir +os.path.sep+decompilation_dir+'_PAPIFeature.json','w') as f_write4:
            f_write4.write(json.dumps(PAPIDict))

        with open('Data'+os.path.sep+dir +os.path.sep+decompilation_dir+'.Features','w') as f_write0:
            for key in API_FrqDict:
                for i in range(int(API_FrqDict.get(key))):
                    print >> f_write0,key
            for key in IA_FrqDict:
                for i in range(int(IA_FrqDict.get(key))):
                    print >> f_write0,key
            for key in PAPIDict:
                for i in range(len(PAPIDict.get(key))):
                    print >> f_write0,key
        os.system('chmod -R 777 '+decompilation_dir)
        shutil.rmtree(decompilation_dir)

def NewLineTokenizer (str):
    return str.split('\n')


def Classification(MalwareCorpus,
                   GoodwareCorpus,
                   Split):

    f = open('Data'+os.path.sep+'ClassificationReport.txt','w')
    origin=sys.stdout
    sys.stdout=f
    # step 1: split all samples to training set and test set (3:1)
    logger.debug ("Loading positive and negative samples file basename")
    MalSamples = [os.path.join(MalwareCorpus,f) for f in os.listdir(MalwareCorpus) if f.endswith('.Features')]
    GoodSamples = [os.path.join(GoodwareCorpus,f) for f in os.listdir(GoodwareCorpus) if f.endswith('.Features')]

    logger.info ("All Samples loaded")
    print '# mal samples:', len(MalSamples)
    print '# good samples:', len (GoodSamples)

    #step 1.2 - split the dataset into training and testing sets
    TrainMalSamples, TestMalSamples = train_test_split(MalSamples,
            test_size=Split,
            random_state=randint(0,99))
    TrainGoodSamples, TestGoodSamples = train_test_split(GoodSamples,
            test_size=Split,
            random_state=randint(0,99))
    logger.info ("Training and test sets split randomly")

    TrainMalLabels = np.ones(len(TrainMalSamples)).tolist()
    TestMalLabels = np.ones(len(TestMalSamples)).tolist()
    TrainGoodLabels = np.empty(len(TrainGoodSamples));TrainGoodLabels.fill(-1); TrainGoodLabels = TrainGoodLabels.tolist()
    TestGoodLabels = np.ones(len(TestGoodSamples));TestGoodLabels.fill(-1); TestGoodLabels = TestGoodLabels.tolist()
    logger.info ("All labels created")

    TrainSamples = TrainMalSamples + TrainGoodSamples
    TestSamples = TestMalSamples + TestGoodSamples
    TrainLabels = TrainMalLabels + TrainGoodLabels
    TestLabels = TestMalLabels + TestGoodLabels

    del MalSamples, GoodSamples
    logger.info ("All Samples loaded into training and testing sets")
    print "# Train Samples", len(TrainSamples)
    print "# Train Labels", len(TrainLabels)
    print "# Test Samples", len(TestSamples)
    print "# Test Labels", len(TestLabels)
    #step 2 - feature extracting
    NewLineCVetorizer = CountVectorizer(input=u'filename',
                                              lowercase=False,
                                              token_pattern=None,
                                              tokenizer=NewLineTokenizer,
                                              binary=False,
                                              dtype=np.float64)

    print 'performing count vectorizing'
    To=time.time()
    TrainDocsTermsFVs = NewLineCVetorizer.fit_transform(TrainSamples)


    del TrainSamples
    TestDocsTermsFVs = NewLineCVetorizer.transform(TestSamples)
    del TestSamples
    print time.time()-To
    print 'train term-doc matrix: ', TrainDocsTermsFVs.shape #rowsx cols, rows = docs, cols = features/terms
    print 'test term-doc matrix: ', TestDocsTermsFVs.shape

    #step 3- classification
    Clf = LinearSVC(random_state=0)
    BestModel = Clf.fit (TrainDocsTermsFVs, TrainLabels)
    joblib.dump(BestModel,'Model.pkl')
    # step 4: Evaluate the best model on test set
    PredictedLabels = BestModel.predict(TestDocsTermsFVs)
    Accuracy = np.mean(PredictedLabels == TestLabels)
    print time.time()-To
    print "Test Set Accuracy = ", Accuracy
    print(metrics.classification_report(TestLabels,
                PredictedLabels, target_names=['Goodware', 'Malware']))
    print 'Top features'
    print '-----------'
    Vocab = NewLineCVetorizer.get_feature_names()
    joblib.dump(Vocab,'Vocab.pkl')
    FeautureImportances = Clf.coef_[0]
    TopFeatureIndices = FeautureImportances.argsort()[-100:][::-1]
    # print TopFeatureIndices[:100]
    for FIndex in TopFeatureIndices:
        print Vocab[FIndex], FeautureImportances[FIndex]
    #for i in range(len(TrainSamples)):
        #FV=TrainDocsTermsFVs.toarray()[i]
        #Res=FV * FeautureImportances
        #TopRes=Res.argsort()[-100:][::-1]
        #print TrainSamples[i],
        #for Sindex in TopRes:
            #print Vocab[Sindex],
        #print
    #for i in range(len(TestSamples)):
        #FV=TestDocsTermsFVs.toarray()[i]
        #Res=FV * FeautureImportances
        #TopRes=Res.argsort()[-100:][::-1]
        #print TestSamples[i],
        #for Sindex in TopRes:
            #if not FV[Sindex]==0: print Vocab[Sindex],
        #print




def main(Maldir,
         Gooddir,
         NumofProcesses,
         FeatureCombination):


    # 1. get features of API, IA, PAPI using Apktool.
    pool = mp.Pool(int(NumofProcesses))
    if not os.path.exists('Metadata'):  os.makedirs('Metadata')
    os.system('chmod 777 Metadata')
    if not os.path.exists('Metadata'+os.path.sep+'Malware'):  os.makedirs('Metadata'+os.path.sep+'Malware')
    os.system('chmod 777 Metadata'+os.path.sep+'Malware')
    if not os.path.exists('Metadata'+os.path.sep+'Benign'):  os.makedirs('Metadata'+os.path.sep+'Benign')
    os.system('chmod 777 Metadata'+os.path.sep+'Benign')
    if not os.path.exists('Data'):  os.makedirs('Data')
    os.system('chmod 777 Data')
    if not os.path.exists('Data'+os.path.sep+'Malware'):  os.makedirs('Data'+os.path.sep+'Malware')
    os.system('chmod 777 Data'+os.path.sep+'Malware')
    if not os.path.exists('Data'+os.path.sep+'Benign'):  os.makedirs('Data'+os.path.sep+'Benign')
    os.system('chmod 777 Data'+os.path.sep+'Benign')

    for root,dirs,files in os.walk(Maldir):
        for file in files:
            if file.endswith('.apk'):
                filename= os.path.join(root,file)
                pool.apply_async(FeatureExtraction, args = (filename,'Malware',FeatureCombination))
            else:
                print "This is not a valid Android application"
    for root,dirs,files in os.walk(Gooddir):
        for file in files:
            if file.endswith('.apk'):
                filename= os.path.join(root,file)
                pool.apply_async(FeatureExtraction, args = (filename,'Benign',FeatureCombination))
            else:
                print "This is not a valid Android application"
    pool.close()
    pool.join()


    # 2.1 get features of FLOW, using FlowDroid
    #if FeatureCombination[3]=='1':
        #getFlowmain(Maldir,Maldir+os.path.sep+'Matedata',0)
        #getFlowmain(Gooddir,Gooddir+os.path.sep+'Matedata',0)
    # 2.2 combine all features together
    #for root,dirs,files in os.walk(Maldir+os.path.sep+'Matedata'):
        #for file in files:
            #if file.endswith('FLOWFeature.json'):
                #with open(file,'r') as f:
                    #Flow_Linelist=f.readlines()
                    #AppName=os.path.basename(file)[:-16]
                    #with open(Maldir+os.path.sep+'Data'+os.path.sep+AppName+'.Features','a') as f_a:
                        #for line in Flow_Linelist:
                            #print >> f_a, line
                        #f_a.close()
                    #f.close()
    #for root,dirs,files in os.walk(Gooddir+os.path.sep+'Matedata'):
        #for file in files:
            #if file.endswith('FLOWFeature.json'):
                #with open(file,'r') as f:
                    #Flow_Linelist=f.readlines()
                    #AppName=os.path.basename(file)[:-16]
                    #with open(Gooddir+os.path.sep+'Data'+os.path.sep+AppName+'.Features','a') as f_b:
                        #for line in Flow_Linelist:
                            #print >> f_b, line
                        #f_b.close()
                    #f.close()

    # 3. classification
    Classification('Data'+os.path.sep+'Malware','Data'+os.path.sep+'Benign',0.3)


if __name__ == '__main__':
    
    main(Maldir=sys.argv[1], #absolute path of Mal
         Gooddir=sys.argv[2], #absolute path of Good
         NumofProcesses=sys.argv[3], #Num of multi-processes
         FeatureCombination=sys.argv[4])
