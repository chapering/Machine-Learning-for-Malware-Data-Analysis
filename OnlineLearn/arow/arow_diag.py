import numpy as np
from scipy import sparse
import logging as logger
import time
from collections import defaultdict
from sklearn.metrics import confusion_matrix
from base import ConfidenceWeightedModel
from scipy.sparse import csr_matrix
import random

class ArowDiag(ConfidenceWeightedModel):
    """
    Adaptive Regularization of Weight Vector algorithm with squared hinge loss,
    omitting non-diagonal elements.

    Reference:
    - http://webee.technion.ac.il/people/koby/publications/arow_nips09.pdf

    This model is only applied to binary classification.
    """

    def __init__(self, C = 1, n_iters = 10):

        logger.basicConfig(level=logger.DEBUG)
        logger.info("init starts")

        self.n_scan = n_iters
        self.data = defaultdict()
        self.model = defaultdict()
        self.cache = defaultdict()
        super(ArowDiag, self).__init__(n_iters)
        estimators=[('C', C), ('n_iters', n_iters)]
        self.estimators = estimators
        self.named_estimators = dict(estimators)
        self._init_model(C)

        logger.info("init finished")

    def _load(self, X):
        '''
        Load feature sparse matrix
        :param X: m * n sample feature  matrix, m is the dimension, n is the number of samples
        :return:
        '''
        logger.info("load data starts")

        # load data
        st = time.time()
        self.data["data"] = X
        et = time.time()
        #logger.info("loading data time: %f[s]", (et - st))
        self.data["n_sample"] = self.data["data"].shape[0]
        self.data["f_dim"] = self.data["data"].shape[1] - 1
        self.model["mu"] = csr_matrix(np.zeros(self.data["f_dim"] + 1))
        self.model["S"] = csr_matrix(np.ones(self.data["f_dim"] + 1))

    def _init_model(self, C):
        '''
        Initialise model
        :param C:
        :return:
        '''
        logger.info("init model starts")
        self.model["mu"] = defaultdict()  # model parameter mean
        self.model["S"] = defaultdict()  # model parameter covariance
        self.model["C"] = C  # aggressive parameter
        self.model["warm_start"] = True
        self.model["mu"] = csr_matrix(np.zeros(1))
        self.model["S"] = csr_matrix(np.ones(1))
        logger.info("init model finished")

    def _update(self, sample, label, margin):
        """
        Update model parameter internally.
        update rule is as follows,
        beta = x^TSx + C,
        mu = mu + y(1 - m)Sx /beta, and
        S = S - Sxx^TS / C.
        Arguments:
        - `label`: label = {1, -1}
        - `sample`: sample, or feature vector
        """

        # add bias
        sample = self._add_bias_for_sparse_sample(sample)
        # beta
        beta = (sample.multiply(self.model["S"]).multiply(sample)).sum() + self.model["C"]
        # mu
        norm = sample.multiply(sample)
        mu = self.model["mu"] + self.model["S"].multiply(sample) * label * (1 - margin)/beta
        self.model["mu"] = mu

        # S
        S = self.model["S"] - (self.model["S"].multiply(sample).multiply(sample).multiply(self.model["S"]))/beta
        self.model["S"] = S

    def fit(self, X, y):
        '''
        Fit the model
        :param X: data matrix
        :param y: label list
        :return:
        '''
        self._load(X)
        logger.info("learn starts")
        data = self.data["data"]

        # learn
        st = time.time()
        for j in xrange(0, self.n_scan):
            #logger.debug("iter: %d" % j)
            data_index = range(0, self.data["n_sample"])
            random.shuffle(data_index)
            for i in data_index:
                sample = data[i, 1:]
                label = y[i]
                pred_val = self._predict_value(sample)
                margin = label * pred_val
                if margin < 1:
                    self._update(sample, label, margin)

        logger.info("learn finished")
        et = time.time()
        logger.info("learning time: %f[s]" % (et - st))

    def _predict_value(self, sample):
        """
        predict value of \mu^T * x

        Arguments:
        - `sample`:
        """
        sample = self._add_bias_for_sparse_sample(sample)
        return (self.model["mu"].multiply(sample)).sum()

    def predict(self, sample):
        """
        predict {1, -1} base on \mu^T * x

        Arguments:
        - `sample`:
        """
        sample = sample[0, 1:]
        pred_val = self._predict_value(sample)
        self.cache["pred_val"] = pred_val
        if pred_val >= 0:
            return 1
        else:
            return -1

    def partial_fit(self, sample, label):
        """
        update model.
        Arguments:
        - `sample`: sample, or feature vector
        - `pred_val`: predicted value i.e., mu^T * sample
        """
        margin = label * self.cache["pred_val"]
        sample = sample[0, 1:]
        if margin < 1:
            self._update(sample, label, margin)

if __name__ == '__main__':
    pass
