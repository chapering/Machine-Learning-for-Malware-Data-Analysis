The usage of CW and AROW are very similar, here take CW for example to show the usage of all methods.
  CW.fit(FV(s), Label(s)): This method is used to initially train the classifier or for batch learning. FV(s) can be one or more samples in sparse matrix, Label(s) is(are) corresponding labels for the(each) sample.
  CW.partial_fit(FV, Label): This method is used to update the classifier or for online learning. FV is one sample's feature vector in sparse, Label is the corresponding label.
  CW.Predict(FV): This method is used to predict a test sample. FV is one sample¡¯s feature vector in sparse. It will return the predicted label based on the current weight vector, '1' or '-1'.
  Weight vector = self.model["mu"][1] for positive class, self.model["mu"][-1] for negative class.(Here, since the AROW can only be used as binary classification, the Weight Vector of AROW is self.model["mu"] instead.)


Usage of Classifier Comparison Experiments
In this part, Exp1 is to train all classifiers on Drebin and test on Drebin as well; Exp2 is to train classifiers on VirusShare and test on VirusShare; Exp3 is to train classifiers on whole Drebin dataset but test on whole VirusShare dataset; Exp4 is to train certain dataset with fixed temporal trend samples and test on the rest temporal trend samples.
For python files in Exp1, Exp2 and Exp4, the command line arguments should follow:
python ClassifierComparision.py <Malware Feature Files Dir> <Goodware Feature Files Dir> <Train_Test Split> <Feature File Extension>
python ClassifierComparision_NotSklearn.py <Malware Feature Files Dir> <Goodware Feature Files Dir> £¨for Exp4 <Train_Test Split>£© <Feature File Extension>
Note that for Exp1&2, 'ClassifierComparision_NotSklearn.py' should be running only after the 'ClassifierComparision.py' has been running, the latter one will generate Train & Test samples randomly.

For python files in Exp3, the command line arguments should follow:
python ClassifierComparision.py <Training Malware Feature Files Dir> <Training Goodware Feature Files Dir> <Testing Malware Feature Files Dir> <Testing Goodware Feature Files Dir> <Feature File Extension>
python ClassifierComparision_NotSklearn.py <Training Malware Feature Files Dir> <Training Goodware Feature Files Dir> <Testing Malware Feature Files Dir> <Testing Goodware Feature Files Dir> <Feature File Extension>
There is no strict order in Exp3&4 for the two python files.


Standard Output
The output of python files above will generate 2 txt files for each classifier, one named '*.txt' contains overall classification of the classifier, the other named '*_Metadata.txt' contains some meta data used for error rate plotting.
The Plot.py can be used in every experiment, it is used to plot error rate curves of every classifier, the command line arguments should follow:
python Plot.py 'SVM_*_Metadata.txt' 'PA_*_Metadata.txt' 'Perceptron_*_Metadata.txt' 'SGD_*_Metadata.txt' 'CW_*_Metadata.txt' 'AROW_*_Metadata.txt'
The '*_Metadata.txt' files are generated from python files above, which contains zero-one loss scores of every classifier.
