import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.preprocessing import Normalizer
import os
import sys
import logging
from scipy.spatial.distance import cosine
from sklearn.metrics.pairwise import linear_kernel
import random
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
import scipy.sparse as ssp

import matplotlib  
matplotlib.use('Agg') 

import matplotlib.pyplot as plt
from numpy import ma
from matplotlib import colors, ticker, cm
from matplotlib.mlab import bivariate_normal

#logging level
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('sys.stdout')


def GetFilesWithExtn (RootDir, Familyname, Extn):
    '''
    lllr to "find" command. List all the files from the RootDir with a given Extn
    :param RootDir: root to find files from
    :param Extn: extension to look for
    :return: sorted list of files with a given extension from the root dir and its child dirs
    '''

    FilesToProcess = []
    for Root,Folders,Files in os.walk(RootDir):
        for F in Files:
            if F.endswith(Extn) and (Familyname in F):
                FilesToProcess.append(os.path.join(Root,F))

    FilesToProcess = list(set(FilesToProcess))
    FilesToProcess.sort()
    return FilesToProcess


def NewLineTokenizer (Str):
    return Str.split('\n')

def NewLineTokenizerNoContext (Str):
    StrList = Str.split('\n')
    for Index,Str in enumerate(StrList):
        if '~' in Str:
            StrList[Index] = Str.split('~')[1]
    return StrList


def GetTopVocab(MalwareCorpus,
                   GoodwareCorpus,
                   Familyname,
                   Extn):

    if 'datatxt' in Extn:
        Type = 'Drebin'
    elif 'WL2' in Extn:
        Type = 'WLK'
    elif '.txt' in Extn:
        Type = 'CSBD' 

    MalSamples = GetFilesWithExtn(MalwareCorpus, Familyname, Extn)
    MalSamples.sort()
    GoodSamples = GetFilesWithExtn(GoodwareCorpus, '', Extn)[:len(MalSamples)]
    GoodSamples.sort()
    
    Samples = MalSamples + GoodSamples


    MalLabels = np.ones(len(MalSamples))
    GoodLabels = np.empty(len(GoodSamples)); GoodLabels.fill(-1)

    Labels = np.hstack ((MalLabels, GoodLabels))

    logger.info ("All Samples loaded")
    print '# mal samples:', len(MalSamples)
    print '# ben samples:', len(GoodSamples)

    #step 2 - feature extracting

    TFIDFTransformer = TfidfTransformer()
    NewLineCVectorizer = CountVectorizer(input=u'filename',
                                                  lowercase=True,
                                                  token_pattern=None,
                                                  tokenizer=NewLineTokenizer,
                                                  #binary=True,
                                                  #stop_words=[''],
                                                  dtype=np.float64)

    print 'performing TfidfTransformer and Normalizer'
    TFIDFTransformer = TfidfTransformer()
    normalizer = Normalizer()
    FVs = NewLineCVectorizer.fit_transform(Samples)
    print FVs.shape

    print 'normalizing FVs'
    # TrainFVs = normalizer.fit_transform(TrainFVs)
    # TestFVs = normalizer.transform(TestFVs)
    FVs = TFIDFTransformer.fit_transform(FVs)
    
    if Type == 'Drebin' or Type == 'WLK':
        Clf = LinearSVC(C = 0.1)
    


        BestModel = Clf.fit (FVs, Labels)
    
        Vocab = NewLineCVectorizer.get_feature_names()
        FeatureImportances = BestModel.coef_[0]



        FeatureImportancesSparseArray = ssp.lil_matrix((FVs.shape[1],FVs.shape[1]))
        FeatureImportancesSparseArray.setdiag(FeatureImportances)

        AllFVsTimesW = FVs*FeatureImportancesSparseArray
        AvgFVOfDay = AllFVsTimesW.mean(axis=0)
        AvgFVOfDay = AvgFVOfDay.view(dtype=np.float64).reshape(AvgFVOfDay.shape[1],-1)
        AvgFVOfDay = np.array(AvgFVOfDay).reshape(-1,)
        print AvgFVOfDay.shape
        AvgFVOfDay.dump(Familyname+'_'+Type+'_Weight.txt')
        with open(Familyname+'_'+Type+'.txt','w') as f:
            TopFeatureIndices = AvgFVOfDay.argsort()[-100:][::-1]
            for FIndex in TopFeatureIndices:
                print >> f, Vocab[FIndex]
            # raw_input()

 
    elif Type == 'CSBD':
        Clf = RandomForestClassifier(n_estimators = 100, max_features = "log2", max_depth = None)
        BestModel = Clf.fit (FVs, Labels)
        Vocab = NewLineCVectorizer.get_feature_names()
        AvgFVOfDay = BestModel.feature_importances_
        #print AvgFVOfDay
        #AvgFVOfDay.dump(Familyname+'_'+Type+'_Weight.txt')
        with open(Familyname+'_'+Type+'.txt','w') as f:
            TopFeatureIndices = AvgFVOfDay.argsort()[-100:][::-1]
            for FIndex in TopFeatureIndices:
                print >> f, Vocab[FIndex]
            # raw_input()



def main(MalwareDirName,
         BenignDirName,
         Familyname,
         Extn):


    GetTopVocab(MalwareDirName,
                   BenignDirName,
                   Familyname,
                   Extn)

if __name__ == "__main__":

     main(MalwareDirName=sys.argv[1],
          BenignDirName=sys.argv[2],
          Familyname=sys.argv[3],
          Extn=sys.argv[4])  



