__author__ = 'Vince'
import sys
import os
import logging
from itertools import cycle
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.svm import LinearSVC
from scipy.sparse import *
from scipy import *
import scipy.sparse as ssp
from sklearn.externals import joblib
import shutil
import json
import fnmatch
from Pedal_Exractor import PEDALApp
from Pedal_Exractor import GetPermsUsed
from Pedal_Exractor import GetSusiSrcsSinks


logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('sys.stdout')

def GetFilesWithExtn (RootDir, Prefix, Extn):
    '''
    List all the files from the RootDir with a given Extn
    :param RootDir: root to find files from
    :param Extn: extension to look for
    :return: sorted list of files with a given extension from the root dir and its child dirs
    '''
    FilesToProcess = []
    for Root, Folders, Files in os.walk(RootDir):
        for F in Files:
            if F.startswith(Prefix) and F.endswith(Extn):
                FilesToProcess.append(os.path.join(Root, F))

    FilesToProcess = list(set(FilesToProcess))
    FilesToProcess.sort()
    return FilesToProcess

def NewLineTokenizer(Str):
    '''
    New line tokenizer
    :param Str:
    :return:
    '''
    return Str.split('\n')

def SelectiveTokenizer(Str):
    '''
    Selective tokenizer based on feature combination
    :param Str:
    :return:
    '''
    global FeatureCombination
    a = Str.split('\n')
    if not int(FeatureCombination[0]):
        for elem in a:
            if elem.startswith('comp_'):
                del a[a.index(elem)]
    if not int(FeatureCombination[1]):
        for elem in a:
            if '.permission.' in elem:
                del a[a.index(elem)]
    if not int(FeatureCombination[2]):
        for elem in a:
            if elem.startswith('vi'):
                del a[a.index(elem)]
    if not int(FeatureCombination[3]):
        for elem in a:
            if (elem.startswith('src') or elem.startswith('sink')):
                del a[a.index(elem)]
    if not int(FeatureCombination[4]):
        for elem in a:
            if (elem.endswith('rtpermcheck_yes') or elem.endswith('rtpermcheck_no')):
                del a[a.index(elem)]
    if not int(FeatureCombination[5]):
        for elem in a:
            if (elem.startswith('kw') or elem.startswith('stemmedkw')):
                del a[a.index(elem)]
    return a

def HaveChildPkg(Pkg, PkgList):
    '''
    Judge whether a package has children
    :param Pkg: Package to be checked
    :param PkgList: Package list on every iteration
    :return: 1 for having children, or 0 for do not having children
    '''
    d = 0
    for p in PkgList:
        if Pkg+'.' in p:
            d = 1
    return d

def GetDeepestPkgs(Pkgs):
    '''
    Get deepest packages on every iteration
    :param Pkgs: Package list on every iteration
    :return: Deepest packages
    '''
    DeepestPkgs = []
    for pkg in Pkgs:
        if not HaveChildPkg(pkg, Pkgs):
            DeepestPkgs.append(pkg)
    DeepestPkgs.sort()
    return DeepestPkgs

def GetParPkgs(Pkg, PkgList):
    '''
    Get parent package for a given package
    :param Pkg: Package to be checked
    :param PkgList: Whole package list
    :return: Parent packages
    '''
    ParPkgs = []
    p = Pkg
    while p:
        p = os.path.dirname(p.replace('.', os.sep)).replace(os.sep, '.')
        if p in PkgList:
            ParPkgs.append(p)
    return ParPkgs

def ReadVocab (VocabFName):
    '''
    Read vocabulary for a built model
    :param VocabFName: vocabulary file
    :return:
    '''
    try:
        logger.info('trying to load vocab from'+ VocabFName)
        Vocab = [l.strip() for l in open (VocabFName,'r').xreadlines()]
        return Vocab
    except:
        logger.warning('could not load vocab from {} exiting... '.format(VocabFName))
        exit(0)

def get_model(ModelName):
    '''
    Get the model from built model file
    :param ModelName: Absolute path for the model file
    :return:
    '''
    try:
        logger.info('loading from pickle file {}'.format(ModelName))
        model = joblib.load(ModelName)
        return model
    except:
        logger.warning('could not load model from {} exiting... '.format(ModelName))
        exit(0)

def Classification(file, model, vocabulary):

    # step 1 - reading model, generate feature files
    Vocab = ReadVocab(vocabulary)
    Model = get_model(model)

    global SusiApiSrcMap, SusiApiSinkMap, PScoutWithIntentMap

    with open('SusiAPISrcDict.json', 'r') as f:
        SusiApiSrcMap = json.load(f)
    with open('SusiAPISinkDict.json', 'r') as f:
        SusiApiSinkMap = json.load(f)
    with open('PScoutApiPermMappingWithINTENTs.json', 'r') as f:
        PScoutWithIntentMap = json.load(f)

    ApktoolCommand = "java -jar apktool.jar d -f " + file
    os.system(ApktoolCommand)
    RootSmali = './'+os.path.basename(file).split('.apk')[0]
    print 'Decompiling ' + file
    App = PEDALApp(RootSmali, SusiApiSrcMap, SusiApiSinkMap, PScoutWithIntentMap)
    OPPrefix = os.path.basename(file).split('.apk')[0]

    App.PopulateAPIPermSrcSinkUsages()
    App.PopulateVIIncludes()
    App.PopulateRTPermsUsage()
    App.PopulateCompUsages()
    App.PopulateIdentifierNames()
    App.PopulateKeyWordsFromIdentifiers()
    App.PopulateInternetAccess()

    App.DumpToFile(OPPrefix)

    print 'Deleting decompilation files '+RootSmali+' ...'
    shutil.rmtree(RootSmali)
    print 'Deletion Finished'

    TestSamples = GetFilesWithExtn('Features', OPPrefix, '.Features')
    PkgList = [p.split('_')[-1].split('.Features')[0] for p in TestSamples]
    Pkg2bTested = [p.split('_')[-1].split('.Features')[0] for p in TestSamples]

    # step 2 - feature extracting
    TFIDFTransformer = TfidfTransformer()

    NewLineCVetorizer = CountVectorizer(input=u'filename',
                                        lowercase=True,
                                        token_pattern=None,
                                        binary=True,
                                        vocabulary= Vocab,
                                        tokenizer=SelectiveTokenizer,
                                        dtype=np.float64)

    # step 3 -  classification
    PossitivePkg = []
    while Pkg2bTested:
        DeepestPkgs = GetDeepestPkgs(Pkg2bTested)
        for p in DeepestPkgs:
            PId = PkgList.index(p)
            TestSample = [TestSamples[PId]]
            FeatureContent = open(TestSample[0]).read()
            TestDocsTermsFV = NewLineCVetorizer.fit_transform(TestSample)
            TestFV = TFIDFTransformer.fit_transform(TestDocsTermsFV)
            PredictedLabel = Model.predict(TestFV)
            '''
            f = open(os.path.basename(file)+'_'+p+'_TopFeas.txt', 'w')
            FeautureImportances = Model.feature_importances_

            print >>f, 'Top Features'
            FeatureImportancesSparseArray = ssp.lil_matrix((TestFV.shape[1], TestFV.shape[1]))
            FeatureImportancesSparseArray.setdiag(FeautureImportances)
            AllFVsTimesW = TestFV*FeatureImportancesSparseArray

            AvgFVOfDay = AllFVsTimesW.mean(axis=0)
            AvgFVOfDay = AvgFVOfDay.view(dtype=np.float64).reshape(AvgFVOfDay.shape[1],-1)
            AvgFVOfDay = np.array(AvgFVOfDay).reshape(-1,)
            TopRes = AvgFVOfDay.argsort()[-20:][::-1]
            for Sindex in TopRes:
                print >>f, Vocab[Sindex], AvgFVOfDay[Sindex]
            print >>f, '-'*100
           '''
            if float(PredictedLabel) > 0 and 'internetaccesscheck_yes' in FeatureContent.lower():
                print 'Package'+ p +' is '+ str(float(PredictedLabel))
                PossitivePkg.append(p)
                ParPkgList = GetParPkgs(p, Pkg2bTested)
                for pkg in ParPkgList:
                    del Pkg2bTested[Pkg2bTested.index(pkg)]
                del Pkg2bTested[Pkg2bTested.index(p)]
            else:
                del Pkg2bTested[Pkg2bTested.index(p)]

    with open(os.path.basename(file)+'_AdLib.txt', 'w') as f_w:
        for pospkg in PossitivePkg:
            print >> f_w, pospkg

def main(AppDir, ModelDir='Model.pkl', VocabDir='Vocab.txt'):
    '''
    Classify all apps in a given folder whether contain ad libs
    :param AppDir: Directory that contains apps to be examined
    :param ModelDir: Absolute path of built model
    :param VocabDir: Absolute path of classifier vocabulary
    :return:
    '''

    with open('SusiAPISrcDict.json', 'r') as f:
        SusiApiSrcMap = json.load(f)
    with open('SusiAPISinkDict.json', 'r') as f:
        SusiApiSinkMap = json.load(f)
    with open('PScoutApiPermMappingWithINTENTs.json', 'r') as f:
        PScoutWithIntentMap = json.load(f)

    for root, dirs, files in os.walk(AppDir):
        for file in files:
            if file.endswith('.apk'):
                Classification(os.path.join(root, file), ModelDir, VocabDir)

if __name__ == "__main__":

     FeatureCombination = sys.argv[4]
     main(AppDir=sys.argv[1],
          ModelDir=sys.argv[2],
          VocabDir=sys.argv[3])
